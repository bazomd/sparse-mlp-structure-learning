experiment_num: 3

Parameters:
random_state=3
population=30
search_space_dimensions=(12, 6, 3)
learning_rate=0.01
alpha=0.7
epochs=450
patience=10
early_stopping_threshold=0.0001
num_init_connections=(7, 3)
connections_limits=((2, 10000), (2, 100000))


Configurations:
iterations: 30, w=0.9, c_1=2, c_2=2, epsilon=0.4
iterations: 30, w=0.9, c_1=4, c_2=4, epsilon=0.4
iterations: 20, w=0.9, c_1=1, c_2=10, epsilon=0.4


best particle:
train accuracy: 0.9083333333333333
test accuracy: 0.9333333333333333
test recall: 0.9333333333333332
test precision: 0.9444444444444445
test f1 score: 0.9326599326599326

number of connections: (3, 3)

connected features:
sw: [2. 3.]
pl: [5.1 6.9]
pw: [1.3 2.5]

first connectivity matrix:
[[0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 1 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]]

second connectivity matrix:
[[0 0 1]
 [1 0 0]
 [0 0 0]
 [0 0 0]
 [0 0 0]
 [1 0 0]]

first layer weights:
tensor(indices=tensor([[ 0,  1,  5],
                       [ 9,  4, 11]]),
       values=tensor([ 3.9577, -4.4593,  4.5620]),
       size=(6, 12), nnz=3, layout=torch.sparse_coo)
first layer biases:
Parameter containing:
tensor([-1.9761,  2.1008, -0.0885, -0.2024,  0.2466, -2.2054],
       requires_grad=True)
second layer weights:
tensor(indices=tensor([[0, 0, 2],
                       [1, 5, 0]]),
       values=tensor([ 3.4998, -4.1346,  4.9179]),
       size=(3, 6), nnz=3, layout=torch.sparse_coo)
second layer biases:
Parameter containing:
tensor([-0.2863,  0.3763, -1.5873], requires_grad=True)

Runtime: 833.69 seconds