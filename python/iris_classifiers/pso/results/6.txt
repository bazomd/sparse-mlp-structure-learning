experiment_num: 6

Parameters:
random_state=6
population=30
search_space_dimensions=(12, 6, 3)
learning_rate=0.01
alpha=0.7
epochs=450
patience=10
early_stopping_threshold=0.0001
num_init_connections=(7, 3)
connections_limits=((2, 10000), (2, 100000))


Configurations:
iterations: 30, w=0.9, c_1=2, c_2=2, epsilon=0.4
iterations: 30, w=0.9, c_1=4, c_2=4, epsilon=0.4
iterations: 20, w=0.9, c_1=1, c_2=10, epsilon=0.4


best particle:
train accuracy: 0.9
test accuracy: 0.9
test recall: 0.9090909090909092
test precision: 0.923076923076923
test f1 score: 0.9038901601830664

number of connections: (4, 2)

connected features:
sw: [2. 3.]
pl: [4.35 5.1 ]
pl: [5.1 6.9]

first connectivity matrix:
[[0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 1 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 1 0 0 0]
 [0 0 1 1 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]]

second connectivity matrix:
[[0 0 0]
 [0 0 0]
 [0 1 0]
 [1 0 0]
 [0 0 0]
 [0 0 0]]

first layer weights:
tensor(indices=tensor([[2, 2, 3, 3],
                       [8, 9, 4, 9]]),
       values=tensor([ 3.1134, -3.7107,  3.6545,  4.6530]),
       size=(6, 12), nnz=4, layout=torch.sparse_coo)
first layer biases:
Parameter containing:
tensor([ 0.1021, -0.0897,  0.6160, -2.5424, -0.2701,  0.2728],
       requires_grad=True)
second layer weights:
tensor(indices=tensor([[0, 1],
                       [3, 2]]),
       values=tensor([-4.7580,  4.7106]),
       size=(3, 6), nnz=2, layout=torch.sparse_coo)
second layer biases:
Parameter containing:
tensor([ 2.2905, -2.4444, -0.0610], requires_grad=True)

Runtime: 840.63 seconds