experiment_num: 42

Parameters:
random_state=42
population=30
search_space_dimensions=(12, 6, 3)
learning_rate=0.01
alpha=0.7
epochs=450
patience=10
early_stopping_threshold=0.0001
num_init_connections=(7, 3)
connections_limits=((2, 10000), (2, 100000))


Configurations:
iterations: 30, w=0.9, c_1=2, c_2=2, epsilon=0.4
iterations: 30, w=0.9, c_1=4, c_2=4, epsilon=0.4
iterations: 20, w=0.9, c_1=1, c_2=10, epsilon=0.4


best particle:
train accuracy: 0.8166666666666667
test accuracy: 0.9666666666666667
test recall: 0.9696969696969697
test precision: 0.9666666666666667
test f1 score: 0.9665831244778613

number of connections: (4, 2)

connected features:
sl: [6.4 7.9]
sw: [3.  4.4]
pl: [4.35 5.1 ]
pw: [1.3 2.5]

first connectivity matrix:
[[0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 1 0]
 [0 0 0 0 0 0]
 [0 0 0 1 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 1 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 1 0 0]]

second connectivity matrix:
[[0 0 0]
 [0 0 0]
 [0 0 0]
 [1 0 0]
 [0 0 1]
 [0 0 0]]

first layer weights:
tensor(indices=tensor([[ 3,  3,  4,  4],
                       [ 5, 11,  3,  8]]),
       values=tensor([ 3.8381, -4.5879, -4.4926,  5.5971]),
       size=(6, 12), nnz=4, layout=torch.sparse_coo)
first layer biases:
Parameter containing:
tensor([ 0.1277, -0.0799,  0.0908, -1.3156,  2.7564,  0.0948],
       requires_grad=True)
second layer weights:
tensor(indices=tensor([[0, 2],
                       [3, 4]]),
       values=tensor([ 4.5615, -3.8448]),
       size=(3, 6), nnz=2, layout=torch.sparse_coo)
second layer biases:
Parameter containing:
tensor([-2.0917, -0.0237,  2.9357], requires_grad=True)

Runtime: 486.02 seconds